{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b380630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import sys\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reset và cấu hình logging để hiển thị logs từ chatbot_main.py\n",
    "# Xóa tất cả handlers cũ\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Cấu hình lại logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ],\n",
    "    force=True  # Force reconfiguration\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "sys.path.append('../backend')\n",
    "from chatbot_main import chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d9c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation_history(history):\n",
    "    \"\"\"\n",
    "    Format conversation history từ Gradio thành string\n",
    "    \n",
    "    Args:\n",
    "        history: List of tuples [(user_msg1, bot_msg1), (user_msg2, bot_msg2), ...]\n",
    "                 hoặc None/empty list nếu không có lịch sử\n",
    "    \n",
    "    Returns:\n",
    "        String format của conversation history\n",
    "    \"\"\"\n",
    "    if not history or len(history) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    formatted_history = []\n",
    "    for i, (user_msg, bot_msg) in enumerate(history, 1):\n",
    "        formatted_history.append(f\"Lần {i}:\")\n",
    "        formatted_history.append(f\"Người dùng: {user_msg}\")\n",
    "        formatted_history.append(f\"Chatbot: {bot_msg}\")\n",
    "        formatted_history.append(\"\")  # Dòng trống để phân cách\n",
    "    \n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "def chat_interface(message, history):\n",
    "    \"\"\"\n",
    "    Hàm xử lý chat với lịch sử hội thoại\n",
    "    \n",
    "    Args:\n",
    "        message: Tin nhắn từ người dùng\n",
    "        history: Lịch sử hội thoại (list of tuples)\n",
    "    \n",
    "    Returns:\n",
    "        Phản hồi từ chatbot\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Format conversation history\n",
    "        history_text = format_conversation_history(history)\n",
    "        \n",
    "        # Kết hợp lịch sử với message hiện tại\n",
    "        if history_text:\n",
    "            # Nếu có lịch sử, đưa vào user_query để backend có thể sử dụng\n",
    "            enhanced_message = f\"\"\"Lịch sử hội thoại trước đó:\n",
    "{history_text}\n",
    "\n",
    "Câu hỏi hiện tại: {message}\"\"\"\n",
    "        else:\n",
    "            # Nếu không có lịch sử, chỉ dùng message\n",
    "            enhanced_message = message\n",
    "        \n",
    "        # Gọi chatbot backend (logging sẽ tự động in ra từ chatbot_main.py)\n",
    "        response = chatbot_response.invoke(enhanced_message)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "        return f\"Xin lỗi, đã xảy ra lỗi: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe9a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lebaminhphuc/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:27:44,316 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Tạo giao diện Gradio với ChatInterface\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    title=\"Chatbot Y tế\",\n",
    "    description=\"\",\n",
    "    examples=[\n",
    "        \"Thuốc Paracetamol có tác dụng gì?\",\n",
    "        \"Cách sử dụng thuốc giảm đau an toàn?\",\n",
    "        \"Tôi bị đau đầu nên uống thuốc gì?\",\n",
    "        \"Thuốc kháng sinh có tác dụng phụ gì?\",\n",
    "        \"Cách bảo quản thuốc đúng cách?\"\n",
    "    ],\n",
    "    theme=gr.themes.Default(\n",
    "        primary_hue=\"blue\",\n",
    "        secondary_hue=\"sky\",\n",
    "        neutral_hue=\"slate\",\n",
    "        font=[\"Inter\", \"Segoe UI\", \"Roboto\", \"Helvetica Neue\", \"Arial\", \"sans-serif\"],\n",
    "        font_mono=[\"Fira Code\", \"Consolas\", \"Monaco\", \"monospace\"]\n",
    "    ).set(\n",
    "        body_background_fill=\"white\",\n",
    "        body_text_color=\"#1f2937\",\n",
    "        body_text_size=\"16px\",\n",
    "        button_primary_background_fill=\"#3b82f6\",\n",
    "        button_primary_text_color=\"white\",\n",
    "        block_title_text_color=\"#111827\",\n",
    "        block_title_text_size=\"20px\",\n",
    "        block_title_text_weight=\"600\",\n",
    "        block_label_text_color=\"#374151\",\n",
    "        block_label_text_size=\"15px\",\n",
    "        block_label_text_weight=\"500\",\n",
    "        input_background_fill=\"white\",\n",
    "        input_text_size=\"16px\",\n",
    "    ),\n",
    "    css=\"\"\"\n",
    "    .message {\n",
    "        font-size: 16px !important;\n",
    "        line-height: 1.6 !important;\n",
    "    }\n",
    "\n",
    "\n",
    "    h1 {\n",
    "        font-weight: 700 !important;\n",
    "        letter-spacing: -0.02em !important;\n",
    "        text-align: center !important;\n",
    "    }\n",
    "    .gradio-container p {\n",
    "        text-align: center !important;\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "2025-11-28 19:27:44,989 - INFO - HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:27:45,183 - INFO - HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:27:58,625 - INFO - Kiem tra thong tin nguoi dung \n",
      "\n",
      "\n",
      "2025-11-28 19:28:04,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:04,809 - INFO - Thong tin khong du hoac khong lien quan, tra ve thong bao \n",
      "\n",
      "\n",
      "2025-11-28 19:28:21,993 - INFO - Kiem tra thong tin nguoi dung \n",
      "\n",
      "\n",
      "2025-11-28 19:28:24,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:24,172 - INFO - Cap nhat long term memory \n",
      "\n",
      "\n",
      "2025-11-28 19:28:24,178 - INFO - Lay data long term memory \n",
      "\n",
      "\n",
      "2025-11-28 19:28:24,197 - INFO - Mo rong query \n",
      "\n",
      "\n",
      "2025-11-28 19:28:25,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:29,890 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:32,925 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:33,184 - INFO - Lay document phu hop \n",
      "\n",
      "\n",
      "2025-11-28 19:28:34,921 - INFO - HTTP Request: POST https://2f41421b-1095-4cb3-8625-6df79db78d48.us-east-1-1.aws.cloud.qdrant.io:6333/collections/embedding_data/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:35,642 - INFO - HTTP Request: POST https://2f41421b-1095-4cb3-8625-6df79db78d48.us-east-1-1.aws.cloud.qdrant.io:6333/collections/embedding_data/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:35,697 - INFO - Kiem tra do dai document\n",
      "2025-11-28 19:28:40,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:28:40,498 - INFO - Tra loi nguoi dung\n",
      "2025-11-28 19:28:43,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:24,153 - INFO - Kiem tra thong tin nguoi dung \n",
      "\n",
      "\n",
      "2025-11-28 19:29:26,363 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:26,504 - INFO - Cap nhat long term memory \n",
      "\n",
      "\n",
      "2025-11-28 19:29:26,510 - INFO - Lay data long term memory \n",
      "\n",
      "\n",
      "2025-11-28 19:29:26,511 - INFO - Mo rong query \n",
      "\n",
      "\n",
      "2025-11-28 19:29:27,917 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:29,770 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:32,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:32,299 - INFO - Lay document phu hop \n",
      "\n",
      "\n",
      "2025-11-28 19:29:33,919 - INFO - HTTP Request: POST https://2f41421b-1095-4cb3-8625-6df79db78d48.us-east-1-1.aws.cloud.qdrant.io:6333/collections/embedding_data/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:34,651 - INFO - HTTP Request: POST https://2f41421b-1095-4cb3-8625-6df79db78d48.us-east-1-1.aws.cloud.qdrant.io:6333/collections/embedding_data/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-11-28 19:29:34,754 - INFO - Kiem tra do dai document\n",
      "2025-11-28 19:29:34,858 - INFO - Tra loi nguoi dung\n",
      "2025-11-28 19:29:37,717 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Khởi chạy ứng dụng\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share=False,  # Đặt True nếu muốn chia sẻ link public\n",
    "        show_error=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3b056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279f10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
